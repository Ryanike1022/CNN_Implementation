{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7434a0",
   "metadata": {},
   "source": [
    "In this notebook, we're going to implement Convo2D from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb291c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae78b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Conv2D: \n",
      "\n",
      "[[ 7.  7.  0.]\n",
      " [13. 13.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def conv2d(input, kernel, padding = 0, stride = 1):\n",
    "    input_height, input_width = input.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    #calculate output dimentsions\n",
    "    output_height = (input_height - kernel_height + 2*padding)//stride +1\n",
    "    output_width = (input_width - kernel_width + 2*padding)//stride +1\n",
    "\n",
    "    #padding to input if needed\n",
    "    if padding > 0:\n",
    "        padded_input = np.zeros((input_height + 2*padding, input_width + 2*padding))\n",
    "        padded_input[padding:padding + input_height, padding: padding + input_width] = input\n",
    "    else:\n",
    "        padded_input = input\n",
    "\n",
    "    #initilize output\n",
    "    output = np.zeros((output_height, output_width))\n",
    "\n",
    "    #perform convulation\n",
    "    for i in range(output_height):\n",
    "        for j in range (output_width):\n",
    "            output[i,j] = np.sum(padded_input[i*stride: i*stride + kernel_height, j*stride: j*stride + kernel_width] * kernel)\n",
    "\n",
    "    return output\n",
    "\n",
    "input_matrix = np.array([\n",
    "    [1,2,3,0,0],\n",
    "    [4,5,6,0,0],\n",
    "    [7,8,9,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]\n",
    "])\n",
    "\n",
    "kernel_matrix = np.array([\n",
    "    [1,0,1],\n",
    "    [1,0,1],\n",
    "    [1,0,1]\n",
    "])\n",
    "\n",
    "output_matrix = conv2d(input_matrix, kernel_matrix, padding = 1, stride = 2)\n",
    "print(\"Our Conv2D: \\n\")\n",
    "print(output_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf234922",
   "metadata": {},
   "source": [
    "Now, we code this using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbda6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch conv2d output: \n",
      "\n",
      "[[ 7.  7.  0.]\n",
      " [13. 13.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor(input_matrix, dtype = torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "kernel_tensor = torch.tensor(kernel_matrix, dtype = torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "conv = nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 3, padding = 1, stride = 2, bias = False)\n",
    "conv.weight.data = kernel_tensor\n",
    "\n",
    "output_tensor = conv(input_tensor)\n",
    "output_pytorch = output_tensor.squeeze().detach().numpy()\n",
    "\n",
    "print(\"PyTorch conv2d output: \\n\")\n",
    "print(output_pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734131fc",
   "metadata": {},
   "source": [
    "Putting it all together with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbd36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Javascript\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdddef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fa6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datast and DataLoaders configured successsfully\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download = False, transform = transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                         shuffle=True, num_workers=2) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car','bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(\"Datast and DataLoaders configured successsfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "687739dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized successfully\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(\"Network initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b669679",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f67f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.239\n",
      "[1,  4000] loss: 1.850\n",
      "[1,  6000] loss: 1.689\n",
      "[1,  8000] loss: 1.551\n",
      "[1, 10000] loss: 1.518\n",
      "[1, 12000] loss: 1.450\n",
      "[2,  2000] loss: 1.399\n",
      "[2,  4000] loss: 1.375\n",
      "[2,  6000] loss: 1.347\n",
      "[2,  8000] loss: 1.335\n",
      "[2, 10000] loss: 1.293\n",
      "[2, 12000] loss: 1.270\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013945d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
